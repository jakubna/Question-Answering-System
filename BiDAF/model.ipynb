{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.platform import gfile\n",
    "import logging\n",
    "import time\n",
    "import tensorflow_addons as tfa\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "logging.basicConfig(stream = sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_epochs = 3\n",
    "    batch_size = 1\n",
    "    train_embeddings=0\n",
    "    max_gradient_norm=-1\n",
    "    hidden_state_size=20\n",
    "    embedding_size=10\n",
    "    data_dir=\"data/preprocessed\"\n",
    "    vocab_path=\"vocabulary/vocab.dat\"\n",
    "    embed_path=\"glove_vectors/_vectors.npz\"\n",
    "    dropout_val=1.0\n",
    "    train_dir=\"models_lstm_basic\"\n",
    "    use_match=0\n",
    "    \n",
    "\n",
    "    def get_paths(mode):\n",
    "        question = \"data/preprocessed/\"+str(mode)+\".ids.question\" \n",
    "        context = \"data/preprocessed/\"+str(mode)+\".ids.context\" \n",
    "        answer = \"data/preprocessed/\"+str(mode)+\".span\"\n",
    "\n",
    "        return question, context, answer \n",
    "\n",
    "    question_train, context_train, answer_train = get_paths(\"train\")\n",
    "    question_dev ,context_dev ,answer_dev = get_paths(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ is 2.1.0\n",
      "tf.keras.__version__ is: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class squad_dataset(object):\n",
    "    def __init__(self, question_file, context_file, answer_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filename: path to the files\n",
    "        \"\"\"\n",
    "        self.question_file = question_file\n",
    "        self.context_file = context_file\n",
    "        self.answer_file = answer_file\n",
    "\n",
    "        self.length = None\n",
    "\n",
    "    def iter_file(self, filename):\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                line = line.strip().split(\" \")\n",
    "                line = map(lambda tok: int(tok), line)\n",
    "                yield line\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        niter = 0\n",
    "\n",
    "        question_file_iter = self.iter_file(self.question_file)\n",
    "        answer_file_iter = self.iter_file(self.answer_file)\n",
    "        context_file_iter = self.iter_file(self.context_file)\n",
    "\n",
    "        for question, context, answer in zip(question_file_iter, context_file_iter, answer_file_iter):\n",
    "            yield list(question),list(context), list(answer)\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Iterates once over the corpus to set and store length\n",
    "        \"\"\"\n",
    "        if self.length is None:\n",
    "            self.length = 0\n",
    "            for _ in self:\n",
    "                self.length += 1\n",
    "\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trimmed_glove_vectors(filename):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filename: path to the npz file\n",
    "    Returns:\n",
    "        nmatrix of embeddings (np array)\n",
    "    \"\"\"\n",
    "    return np.load(filename)[\"glove\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vocab(vocab_path):\n",
    "    if gfile.Exists(vocab_path):\n",
    "        rev_vocab = [] \n",
    "        with tf.io.gfile.GFile(vocab_path, mode=\"rb\") as f:\n",
    "            rev_vocab.extend(f.readlines())\n",
    "        rev_vocab = [line.strip(b'\\n') for line in rev_vocab]\n",
    "        vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])\n",
    "        return vocab, rev_vocab\n",
    "    else:\n",
    "        raise ValueError(\"Vocabulary file %s not found.\", vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "train = squad_dataset(config.question_train, config.context_train, config.answer_train)\n",
    "dev = squad_dataset(config.question_dev, config.context_dev, config.answer_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clear_dictonary(vocab):\n",
    "    dict_1 = {}\n",
    "    i=0\n",
    "    for k in vocab:\n",
    "        k = re.sub(r'.*b\\'', '\\'', str(k)).replace('\\'','')\n",
    "        dict_1.update({k:i})\n",
    "        i+=1\n",
    "    return dict_1\n",
    "\n",
    "def clear_list(dirty_list):\n",
    "    clean_list = []\n",
    "    for x in dirty_list:\n",
    "        clean_list.append(re.sub(r'.*b\\'', '\\'', str(x)).replace('\\'',''))\n",
    "    return clean_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = config.embed_path\n",
    "vocab_path = config.vocab_path\n",
    "vocab, rev_vocab = initialize_vocab(vocab_path)\n",
    "vocab1 = clear_dictonary(vocab)\n",
    "rev_vocab1 = clear_list(rev_vocab)\n",
    "embeddings = get_trimmed_glove_vectors(embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_sequences(sequences, pad_tok, max_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: a generator of list or tuple\n",
    "        pad_tok: the char to pad with\n",
    "    Returns:\n",
    "        a list of list where each sublist has same length\n",
    "    \"\"\"\n",
    "    sequence_padded, sequence_length = [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        seq = list(seq)\n",
    "        seq_ = seq[:max_length] + [pad_tok]*max(max_length - len(seq), 0)\n",
    "        sequence_padded +=  [seq_]\n",
    "        sequence_length += [min(len(seq), max_length)]\n",
    "\n",
    "    return np.array(sequence_padded), np.array(sequence_length)\n",
    "\n",
    "def pad_sequences(sequences, pad_tok):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: a generator of list or tuple\n",
    "        pad_tok: the char to pad with\n",
    "    Returns:\n",
    "        a list of list where each sublist has same length\n",
    "    \"\"\"\n",
    "    max_length = max([len(list(x)) for x in sequences])\n",
    "    sequence_padded, sequence_length = _pad_sequences(sequences, \n",
    "                                            pad_tok, max_length)\n",
    "\n",
    "    return sequence_padded, sequence_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "question_ids = tf.placeholder(tf.int32, shape = [None, None], name = \"question_ids\")\n",
    "passage_ids = tf.placeholder(tf.int32, shape = [None, None], name = \"passage_ids\")\n",
    "\n",
    "question_lengths = tf.placeholder(tf.int32, shape=[None], name=\"question_lengths\")\n",
    "passage_lengths = tf.placeholder(tf.int32, shape = [None], name = \"passage_lengths\")\n",
    "\n",
    "labels = tf.placeholder(tf.int32, shape = [None, 2], name = \"gold_labels\")\n",
    "dropout = tf.placeholder(tf.float32, shape=[], name = \"dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(questions, contexts, answers, dropout_val):\n",
    "    \"\"\"\n",
    "    -arg questions: A list of list of ids representing the question sentence\n",
    "    -arg contexts: A list of list of ids representing the context paragraph\n",
    "    -arg dropout_val: A float representing the keep probability for dropout \n",
    "\n",
    "    :return: dict {placeholders: value}\n",
    "    \"\"\"\n",
    "\n",
    "    padded_questions, question_length = pad_sequences(questions, 0)\n",
    "    padded_contexts, passage_length = pad_sequences(contexts, 0)\n",
    "\n",
    "\n",
    "    feed = {\n",
    "        question_ids : padded_questions,\n",
    "        passage_ids : padded_contexts,\n",
    "        question_lengths : question_length,\n",
    "        passage_lengths : passage_length,\n",
    "        labels : answers,\n",
    "        dropout : dropout_val\n",
    "    }\n",
    "\n",
    "    return feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-446d869b27fc>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-12-446d869b27fc>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"vocab_embeddings\"):\n",
    "    _word_embeddings = tf.Variable(embeddings, name=\"_word_embeddings\", dtype=tf.float32, trainable= config.train_embeddings)\n",
    "    question_emb = tf.nn.embedding_lookup(_word_embeddings, question_ids, name = \"question\") # (-1, Q, D)\n",
    "    passage_emb = tf.nn.embedding_lookup(_word_embeddings, passage_ids, name = \"passage\") # (-1, P, D)\n",
    "    # Apply dropout\n",
    "    question = tf.nn.dropout(question_emb, config.dropout_val)\n",
    "    passage  = tf.nn.dropout(passage_emb, config.dropout_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(inputs, masks, encoder_state_input = None):\n",
    "    \"\"\"\n",
    "    :param inputs: vector representations of question and passage (a tuple) \n",
    "    :param masks: masking sequences for both question and passage (a tuple)\n",
    "\n",
    "    :param encoder_state_input: (Optional) pass this as initial hidden state\n",
    "                                to tf.nn.dynamic_rnn to build conditional representations\n",
    "    :return: an encoded representation of the question and passage.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    question, passage = inputs\n",
    "    masks_question, masks_passage = masks    \n",
    "\n",
    "    # read passage conditioned upon the question\n",
    "    with tf.variable_scope(\"encoded_question\"):\n",
    "        lstm_cell_fw_question = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        lstm_cell_bw_question = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        encoded_question, (q_rep, _) = tf.nn.bidirectional_dynamic_rnn(lstm_cell_fw_question, lstm_cell_bw_question, question, masks_question, dtype=tf.float32) # (-1, Q, H)\n",
    "\n",
    "    with tf.variable_scope(\"encoded_passage\"):\n",
    "        lstm_cell_fw_passage  = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        lstm_cell_bw_passage  = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        encoded_passage, (p_rep, _) =   tf.nn.bidirectional_dynamic_rnn(lstm_cell_fw_passage, lstm_cell_bw_passage, passage, masks_passage, dtype=tf.float32) # (-1, P, H)\n",
    "\n",
    "    # Merging both the outputs of the bi-lstm models\n",
    "    encoded_question = tf.concat(axis = 2, values = encoded_question)\n",
    "    encoded_passage = tf.concat(axis = 2, values = encoded_passage)\n",
    "\n",
    "    # outputs beyond sequence lengths are masked with 0s\n",
    "    return encoded_question, encoded_passage , q_rep, p_rep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reverse(input_, seq_lengths, seq_dim, batch_dim):\n",
    "    if seq_lengths is not None:\n",
    "        return array_ops.reverse_sequence(\n",
    "            input=input_, seq_lengths=seq_lengths,\n",
    "            seq_dim=seq_dim, batch_dim=batch_dim)\n",
    "    else:\n",
    "        return array_ops.reverse(input_, axis=[seq_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match LSTM\n",
    "def run_match_lstm(encoded_rep, masks):\n",
    "    encoded_question, encoded_passage = encoded_rep\n",
    "    masks_question, masks_passage = masks\n",
    "    \n",
    "    match_lstm_cell_attention_fn = lambda curr_input, state : tf.concat([curr_input, state], axis = -1)\n",
    "    query_depth = encoded_question.get_shape()[-1]\n",
    "\n",
    "    with tf.variable_scope(\"match_lstm_attender\"):\n",
    "        attention_mechanism_match_lstm = tfa.seq2seq.BahdanauAttention(query_depth, encoded_question, memory_sequence_length = masks_question)\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        lstm_attender  =  tfa.seq2seq.AttentionWrapper(cell, attention_mechanism_match_lstm, output_attention = False, cell_input_fn = match_lstm_cell_attention_fn)\n",
    "    \n",
    "        # we don't mask the passage because masking the memories will be handled by the pointerNet\n",
    "        reverse_encoded_passage = _reverse(encoded_passage, masks_passage, 1, 0)\n",
    "    \n",
    "        output_attender_fw, _ = tf.nn.dynamic_rnn(lstm_attender, encoded_passage, dtype=tf.float32, scope =\"rnn\")    \n",
    "        output_attender_bw, _ = tf.nn.dynamic_rnn(lstm_attender, reverse_encoded_passage, dtype=tf.float32, scope = \"rnn\")\n",
    "    \n",
    "        output_attender_bw = _reverse(output_attender_bw, masks_passage, 1, 0)\n",
    "    \n",
    "    output_attender = tf.concat([output_attender_fw, output_attender_bw], axis = -1) # (-1, P, 2*H)\n",
    "    return output_attender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Pointer\n",
    "def run_answer_ptr(output_attender, masks, labels):\n",
    "    #batch_size = tf.shape(output_attender)[0]\n",
    "    masks_question, masks_passage = masks\n",
    "    labels = tf.unstack(labels, axis=1) \n",
    "    \n",
    "    answer_ptr_cell_input_fn = lambda curr_input, context : context # independent of question\n",
    "    query_depth_answer_ptr = output_attender.get_shape()[-1]\n",
    "    \n",
    "    with tf.variable_scope(\"answer_ptr_attender\"):\n",
    "        attention_mechanism_answer_ptr = tfa.seq2seq.BahdanauAttention(query_depth_answer_ptr , output_attender, memory_sequence_length = masks_passage)\n",
    "    \n",
    "        # output attention is true because we want to output the attention values\n",
    "        cell_answer_ptr = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, state_is_tuple = True )\n",
    "        answer_ptr_attender = tfa.seq2seq.AttentionWrapper(cell_answer_ptr, attention_mechanism_answer_ptr, cell_input_fn = answer_ptr_cell_input_fn)\n",
    "        logits, _ = tf.nn.static_rnn(answer_ptr_attender, labels, dtype = tf.float32)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "def decode(encoded_rep, q_rep, masks, labels):\n",
    "    \"\"\"\n",
    "    takes in a knowledge representation\n",
    "    and output a probability estimation over\n",
    "    all paragraph tokens on which token should be\n",
    "    the start of the answer span, and which should be\n",
    "    the end of the answer span.\n",
    "\n",
    "    :param knowledge_rep: it is a representation of the paragraph and question,\n",
    "                          decided by how you choose to implement the encoder\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Run match-LSTM + Ans-Ptr\n",
    "    output_attender = run_match_lstm(encoded_rep, masks)\n",
    "    logits = run_answer_ptr(output_attender, masks, labels)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-1fe81d491049>:17: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-14-1fe81d491049>:17: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-14-1fe81d491049>:19: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-14-1fe81d491049>:19: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-15-e4997021fa19>:5: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From <ipython-input-15-e4997021fa19>:5: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "WARNING:tensorflow:From <ipython-input-17-a0bf69569baa>:14: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-17-a0bf69569baa>:14: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-17-a0bf69569baa>:16: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-17-a0bf69569baa>:16: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "# setup_system\n",
    "encoded_question, encoded_passage, q_rep, p_rep = encode([question,passage], [question_lengths,passage_lengths],encoder_state_input = None)\n",
    "encoded_rep = encoded_question, encoded_passage\n",
    "masks = question_lengths,passage_lengths\n",
    "logits = decode(encoded_rep, q_rep, masks, labels)\n",
    "\n",
    "# setup_loss\n",
    "losses= tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits[0], labels=labels[:,0])\n",
    "losses+= tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits[1], labels=labels[:,1])\n",
    "loss = tf.reduce_mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gradient_norm = -1\n",
    "\n",
    "# setup_train_op\n",
    "with tf.variable_scope(\"train_step\"):\n",
    "    adam_optimizer = tf.train.AdamOptimizer()\n",
    "    grads, varss = zip(*adam_optimizer.compute_gradients(loss))\n",
    "\n",
    "    clip_val = max_gradient_norm\n",
    "    \n",
    "    # if -1 then do not perform gradient clipping\n",
    "    if clip_val != -1:\n",
    "        clipped_grads, _ = tf.clip_by_global_norm(grads, max_gradient_norm)\n",
    "        global_grad = tf.global_norm(clipped_grads)\n",
    "        gradients = zip(clipped_grads, varss)\n",
    "    else:\n",
    "        global_grad = tf.global_norm(grads)\n",
    "        gradients = zip(grads, varss)\n",
    "\n",
    "    train_op = adam_optimizer.apply_gradients(gradients)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "        \n",
    "\n",
    "logger = logging.getLogger(\"QASystemLogger\")\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(session, train_dir):\n",
    "    \"\"\"\n",
    "    param: session managed from train.py\n",
    "    param: train_dir : the directory in which models are saved\n",
    "    \"\"\"\n",
    "    ckpt = tf.train.get_checkpoint_state(train_dir)\n",
    "    v2_path = ckpt.model_checkpoint_path + \".index\" if ckpt else \"\"\n",
    "    if ckpt and (tf.gfile.Exists(ckpt.model_checkpoint_path) or tf.gfile.Exists(v2_path)):\n",
    "        logger.info(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "        saver.restore(session, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        logger.info(\"Created model with fresh parameters.\")\n",
    "        session.run(init)\n",
    "        logger.info('Num params: %d' % sum(v.get_shape().num_elements() for v in tf.trainable_variables()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(session, valid):\n",
    "    \"\"\"\n",
    "    valid: a list containing q, c and a.\n",
    "    :return: loss on the valid dataset and the logit values\n",
    "    \"\"\"\n",
    "    q, c, a = valid\n",
    "\n",
    "    # at test time we do not perform dropout.\n",
    "    input_feed =  get_feed_dict(q, c, a, 1.0)\n",
    "\n",
    "    output_feed = [logits]\n",
    "    outputs = session.run(output_feed, input_feed)\n",
    "\n",
    "    return outputs[0][0], outputs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(session, dataset):    \n",
    "    '''\n",
    "    Get the answers for dataset. Independent of how data iteration is implemented\n",
    "    '''\n",
    "    yp, yp2 = test(session, dataset)\n",
    "    a_s, a_e = [], []\n",
    "    for i in range(yp.shape[0]):\n",
    "        _a_s, _a_e = func(yp[i], yp2[i])\n",
    "        a_s.append(_a_s)\n",
    "        a_e.append(_a_e)\n",
    "    \n",
    "    return (np.array(a_s), np.array(a_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Boundary Model with a max span restriction of 15\n",
    "def func(y1, y2):\n",
    "    max_ans = -999999\n",
    "    a_s, a_e= 0,0\n",
    "    num_classes = len(y1)\n",
    "    for i in range(num_classes):\n",
    "        for j in range(15):\n",
    "            if i+j >= num_classes:\n",
    "                break\n",
    "\n",
    "            curr_a_s = y1[i];\n",
    "            curr_a_e = y2[i+j]\n",
    "            if (curr_a_e+curr_a_s) > max_ans:\n",
    "                max_ans = curr_a_e + curr_a_s\n",
    "                a_s = i\n",
    "                a_e = i+j\n",
    "\n",
    "    return (a_s, a_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(session, dataset):\n",
    "    q, c, a = zip(*[[_q, _c, _a] for (_q, _c, _a) in dataset])\n",
    "\n",
    "    sample = len(dataset)\n",
    "\n",
    "    a_s, a_o = answer(session, [q, c, a])\n",
    "    \n",
    "    answers = np.hstack([a_s.reshape([sample, -1]), a_o.reshape([sample,-1])])\n",
    "    gold_answers = np.array([a for (_,_, a) in dataset])\n",
    "    \n",
    "    em_score = 0\n",
    "    em_1 = 0\n",
    "    em_2 = 0\n",
    "    for i in range(sample):\n",
    "        gold_s, gold_e = gold_answers[i]\n",
    "        s, e = answers[i]\n",
    "        if (s==gold_s): em_1 += 1.0\n",
    "        if (e==gold_e): em_2 += 1.0\n",
    "        if (s == gold_s and e == gold_e):\n",
    "            em_score += 1.0\n",
    "    \n",
    "    em_1 /= float(len(answers))\n",
    "    em_2 /= float(len(answers))\n",
    "    logger.info(\"\\nExact match on 1st token: %5.4f | Exact match on 2nd token: %5.4f\\n\" %(em_1, em_2))\n",
    "    \n",
    "    em_score /= float(len(answers))\n",
    "    \n",
    "    return em_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatches(data, minibatch_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: generator of (question, context, answer) tuples\n",
    "        minibatch_size: (int)\n",
    "    Returns: \n",
    "        list of tuples\n",
    "    \"\"\"\n",
    "    question_batch, context_batch, answer_batch = [], [], []\n",
    "\n",
    "    for (q, c, a) in data:\n",
    "        if len(question_batch) == minibatch_size:\n",
    "            yield question_batch, context_batch, answer_batch\n",
    "            question_batch, context_batch, answer_batch = [], [], []\n",
    "        \n",
    "        question_batch.append(q)\n",
    "        context_batch.append(c)\n",
    "        answer_batch.append(a)\n",
    "\n",
    "    if len(question_batch) != 0:\n",
    "        yield question_batch, context_batch, answer_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(session, train):\n",
    "    \"\"\"\n",
    "    Perform one complete pass over the training data and evaluate on dev\n",
    "    \"\"\"\n",
    "\n",
    "    nbatches = (len(train) + config.batch_size - 1) / config.batch_size\n",
    "    prog = Progbar(target=nbatches)\n",
    "\n",
    "    for i, (q_batch, c_batch, a_batch) in enumerate(minibatches(train, config.batch_size)):\n",
    "\n",
    "        # at training time, dropout needs to be on.\n",
    "        input_feed = get_feed_dict(q_batch, c_batch, a_batch, config.dropout_val)\n",
    "\n",
    "        _, train_loss = session.run([train_op, loss], feed_dict=input_feed)\n",
    "        prog.update(i + 1, [(\"train loss\", train_loss)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(session, dataset, train_dir):\n",
    "    \"\"\"\n",
    "    Implement main training loop\n",
    "\n",
    "    :param session: it should be passed in from train.py\n",
    "    :param dataset: a list containing the training and dev data\n",
    "    :param train_dir: path to the directory where you should save the model checkpoint\n",
    "    \n",
    "    :return:\n",
    "    \"\"\"    \n",
    "    if not tf.gfile.Exists(train_dir):\n",
    "        tf.gfile.MkDir(train_dir)\n",
    "\n",
    "    train, dev = dataset\n",
    "    em = evaluate_model(session, dev)\n",
    "    logger.info(\"\\n#-----------Initial Exact match on dev set: %5.4f ---------------#\\n\" %em)\n",
    "\n",
    "    best_em = 0\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        logger.info(\"\\n*********************EPOCH: %d*********************\\n\" %(epoch+1))\n",
    "        run_epoch(session, train)\n",
    "        em = evaluate_model(session, dev)\n",
    "        logger.info(\"\\n#-----------Exact match on dev set: %5.4f #-----------\\n\" %em)\n",
    "        #======== Save model if it is the best so far ========\n",
    "        if (em > best_em):\n",
    "            saver.save(session, \"%s/best_model.chk\" %train_dir)\n",
    "            best_em = em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:QASystemLogger:Created model with fresh parameters.\n",
      "INFO:QASystemLogger:Num params: 1834200\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[11727,700,200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node encoded_passage/bidirectional_rnn/bw/ReverseSequence (defined at <ipython-input-14-1fe81d491049>:24) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nErrors may have originated from an input operation.\nInput Source operations connected to node encoded_passage/bidirectional_rnn/bw/ReverseSequence:\n vocab_embeddings/passage/Identity (defined at <ipython-input-12-446d869b27fc>:4)\t\n passage_lengths (defined at <ipython-input-10-0ec03fd2e236>:8)\n\nOriginal stack trace for 'encoded_passage/bidirectional_rnn/bw/ReverseSequence':\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/asyncio/base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/asyncio/base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-d152e5a41578>\", line 2, in <module>\n    encoded_question, encoded_passage, q_rep, p_rep = encode([question,passage], [question_lengths,passage_lengths],encoder_state_input = None)\n  File \"<ipython-input-14-1fe81d491049>\", line 24, in encode\n    encoded_passage, (p_rep, _) =   tf.nn.bidirectional_dynamic_rnn(lstm_cell_fw_passage, lstm_cell_bw_passage, passage, masks_passage, dtype=tf.float32) # (-1, P, H)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py\", line 493, in bidirectional_dynamic_rnn\n    inputs_reverse = nest.map_structure(_map_reverse, inputs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 568, in map_structure\n    structure[0], [func(*x) for x in entries],\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 568, in <listcomp>\n    structure[0], [func(*x) for x in entries],\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py\", line 491, in _map_reverse\n    batch_axis=batch_axis)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py\", line 480, in _reverse\n    batch_axis=batch_axis)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 3999, in reverse_sequence\n    name=name)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 7776, in reverse_sequence\n    seq_dim=seq_dim, batch_dim=batch_dim, name=name)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1351\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1352\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1444\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[11727,700,200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node encoded_passage/bidirectional_rnn/bw/ReverseSequence}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f03ed2328114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# ====== Load a pretrained model if it exists or create a new one if no pretrained available ======\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-2821dcdbdb03>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(session, dataset, train_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n#-----------Initial Exact match on dev set: %5.4f ---------------#\\n\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b0fa4bbbed58>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(session, dataset)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ma_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-f6db0b81ff50>\u001b[0m in \u001b[0;36manswer\u001b[0;34m(session, dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0manswers\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIndependent\u001b[0m \u001b[0mof\u001b[0m \u001b[0mhow\u001b[0m \u001b[0mdata\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0ma_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-8596ff7ab2bd>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(session, valid)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moutput_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 960\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1183\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1361\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1384\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1386\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[11727,700,200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node encoded_passage/bidirectional_rnn/bw/ReverseSequence (defined at <ipython-input-14-1fe81d491049>:24) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nErrors may have originated from an input operation.\nInput Source operations connected to node encoded_passage/bidirectional_rnn/bw/ReverseSequence:\n vocab_embeddings/passage/Identity (defined at <ipython-input-12-446d869b27fc>:4)\t\n passage_lengths (defined at <ipython-input-10-0ec03fd2e236>:8)\n\nOriginal stack trace for 'encoded_passage/bidirectional_rnn/bw/ReverseSequence':\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/asyncio/base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/asyncio/base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-d152e5a41578>\", line 2, in <module>\n    encoded_question, encoded_passage, q_rep, p_rep = encode([question,passage], [question_lengths,passage_lengths],encoder_state_input = None)\n  File \"<ipython-input-14-1fe81d491049>\", line 24, in encode\n    encoded_passage, (p_rep, _) =   tf.nn.bidirectional_dynamic_rnn(lstm_cell_fw_passage, lstm_cell_bw_passage, passage, masks_passage, dtype=tf.float32) # (-1, P, H)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py\", line 493, in bidirectional_dynamic_rnn\n    inputs_reverse = nest.map_structure(_map_reverse, inputs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 568, in map_structure\n    structure[0], [func(*x) for x in entries],\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 568, in <listcomp>\n    structure[0], [func(*x) for x in entries],\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py\", line 491, in _map_reverse\n    batch_axis=batch_axis)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py\", line 480, in _reverse\n    batch_axis=batch_axis)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 3999, in reverse_sequence\n    name=name)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 7776, in reverse_sequence\n    seq_dim=seq_dim, batch_dim=batch_dim, name=name)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # ====== Load a pretrained model if it exists or create a new one if no pretrained available ======\n",
    "    initialize_model(sess, config.train_dir)\n",
    "    _train(sess, [train, dev], config.train_dir) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
